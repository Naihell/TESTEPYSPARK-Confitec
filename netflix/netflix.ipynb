{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1fuZYfdmenMk1X3INJhfuCmqeYLi8XIXS",
      "authorship_tag": "ABX9TyMFlEMN43aY3EONGt9gJlbX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naihell/TESTEPYSPARK-Confitec/blob/main/netflix/netflix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9slkOqhBpmp",
        "outputId": "15965a08-4a9d-448f-8e4a-e99451c7ff65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 45 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 46.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845514 sha256=a520d82cc040901f4e28fed15b356425e024134d8baee167d87db6610dbd2f9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/59/f5/79a5bf931714dcd201b26025347785f087370a10a3329a899c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ],
      "source": [
        "# Install pyspark\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, current_timestamp, desc, lit, regexp_replace, to_date, to_timestamp\n",
        "from pyspark.sql.types import TimestampType\n",
        "\n",
        "# Create a Spark Session\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "# To fix date casting problems\n",
        "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")\n",
        "# Check Spark Session Information\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "aMRguiTUCiFT",
        "outputId": "e63d1910-9118-4dad-e033-b21ad5350dcb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f86ec0f14d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://30a0766e71ec:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive_path = '/content/drive/MyDrive/confitec_test/OriginaisNetflix.parquet'"
      ],
      "metadata": {
        "id": "i4zwWVpUEOqP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read raw file"
      ],
      "metadata": {
        "id": "B52us9_5E3pG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.parquet(drive_path)"
      ],
      "metadata": {
        "id": "SIVvl35SC7rL"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNiDtepLFWHl",
        "outputId": "c0dc9d00-3060-4938-c0fc-beadf399837c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------------+---------------+---------+--------------------+-------------+--------------+----------+---------+---------+-------+------+-----+--------+--------------------+\n",
            "|               Title|          Genre|    GenreLabels| Premiere|             Seasons|SeasonsParsed|EpisodesParsed|    Length|MinLength|MaxLength| Status|Active|Table|Language|         dt_inclusao|\n",
            "+--------------------+---------------+---------------+---------+--------------------+-------------+--------------+----------+---------+---------+-------+------+-----+--------+--------------------+\n",
            "|      House of Cards|Political drama|political,drama| 1-Feb-13|6 seasons, 73 epi...|            6|            73|42–59 min.|       42|       59|  Ended|     0|Drama| English|2021-03-16T21:20:...|\n",
            "|       Hemlock Grove|Horror/thriller|horror,thriller|19-Apr-13|3 seasons, 33 epi...|            3|            33|45–58 min.|       45|       58|  Ended|     0|Drama| English|2021-03-16T21:20:...|\n",
            "|Orange Is the New...|   Comedy-drama|   comedy-drama|11-Jul-13|6 seasons, 78 epi...|            6|            78|50–92 min.|       50|       92|Renewed|     1|Drama| English|2021-03-16T21:20:...|\n",
            "+--------------------+---------------+---------------+---------+--------------------+-------------+--------------+----------+---------+---------+-------+------+-----+--------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Transformar os campos \"Premiere\" e \"dt_inclusao\" de string para datetime."
      ],
      "metadata": {
        "id": "QN_i5MdKFSHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('Premiere', to_date(col(\"Premiere\"),\"dd-MMM-yy\")) \\\n",
        "      .withColumn('dt_inclusao', df.dt_inclusao.cast(TimestampType()))"
      ],
      "metadata": {
        "id": "-fM1xKq5E_C_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Ordenar os dados por ativos e gênero de forma decrescente, 0 = inativo e 1 = ativo, todos\n",
        "com número 1 devem aparecer primeiro."
      ],
      "metadata": {
        "id": "314HOr7cLl7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sort(df.Active.desc())"
      ],
      "metadata": {
        "id": "5vLWborWHsY2"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Remover linhas duplicadas e trocar o resultado das linhas que tiverem a coluna \"Seasons\"\n",
        "de \"TBA\" para \"a ser anunciado\"."
      ],
      "metadata": {
        "id": "ghl0ViSpMx9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('Seasons', regexp_replace(df.Seasons, 'TBA', 'a ser anunciado')).distinct()"
      ],
      "metadata": {
        "id": "r0LvpS-PMwyO"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Criar uma coluna nova chamada \"Data de Alteração\" e dentro dela um timestamp."
      ],
      "metadata": {
        "id": "iHMXu4ZxOa_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('Data de Alteração', lit(current_timestamp()))"
      ],
      "metadata": {
        "id": "kCn5-qSCOdHa"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Trocar os nomes das colunas de inglês para português, exemplo: \"Title\" para \"Título\"\n",
        "(com acentuação)."
      ],
      "metadata": {
        "id": "kF67szAutea-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumnRenamed('Title', 'Título') \\\n",
        "        .withColumnRenamed('Genre', 'Gênero') \\\n",
        "        .withColumnRenamed('GenreLabels', 'RótulosGênero') \\\n",
        "        .withColumnRenamed('Premiere', 'Estreia') \\\n",
        "        .withColumnRenamed('Seasons', 'Temporadas') \\\n",
        "        .withColumnRenamed('SeasonsParse', 'TemporadasAnalisadas') \\\n",
        "        .withColumnRenamed('EpisodesParsed', 'EpisódiosAnalisados') \\\n",
        "        .withColumnRenamed('Status', 'Status') \\\n",
        "        .withColumnRenamed('Active', 'Ativo') \\\n",
        "        .withColumnRenamed('Table', 'Grade') \\\n",
        "        .withColumnRenamed('Language', 'Idioma')"
      ],
      "metadata": {
        "id": "P3gDUq7Ktruo"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Testar e verificar se existe algum erro de processamento do spark e identificar onde\n",
        "pode ter ocorrido o erro."
      ],
      "metadata": {
        "id": "gzCPs2rqvr80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tive um problema com o casting de data, mas resolvi com o\n",
        "# spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")"
      ],
      "metadata": {
        "id": "49abeZJfvs2b"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Criar apenas 1 .csv com as seguintes colunas que foram nomeadas anteriormente \"Title,\n",
        "Genre, Seasons, Premiere, Language, Active, Status, dt_inclusao, Data de Alteração\" as\n",
        "colunas devem estar em português com header e separadas por \";\"."
      ],
      "metadata": {
        "id": "JhXohR3uwEfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/drive/MyDrive/confitec_test/output'\n",
        "\n",
        "selected_columns = df.select(\n",
        "    'Título',\n",
        "    'Gênero',\n",
        "    'Temporadas',\n",
        "    'Estreia',\n",
        "    'Ativo',\n",
        "    'Status',\n",
        "    'dt_inclusao',\n",
        "    'Data de Alteração'\n",
        ")\n",
        "\n",
        "# Ordenar as colunas novamente\n",
        "selected_columns = selected_columns.sort(selected_columns.Ativo.desc())\n",
        "\n",
        "selected_columns.coalesce(1).write.mode('overwrite').option('header', 'true').csv(output_path)"
      ],
      "metadata": {
        "id": "pW67zDNfv3AG"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Inserir esse .csv dentro de um bucket do AWS s3"
      ],
      "metadata": {
        "id": "6vKlS_B10uIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vou ficar devendo, mas o procedimento é o mesmo."
      ],
      "metadata": {
        "id": "Cn6u9GB402wl"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmaIOHkN1Amu",
        "outputId": "7d42fbb1-2f5a-48aa-9cb4-8db5e3bf309b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+----------+-----+-------+--------------------+--------------------+\n",
            "|              Título|              Gênero|          Temporadas|   Estreia|Ativo| Status|         dt_inclusao|   Data de Alteração|\n",
            "+--------------------+--------------------+--------------------+----------+-----+-------+--------------------+--------------------+\n",
            "| My First First Love|     Romantic comedy|1 season, 8 episodes|2019-04-18|    1|Renewed|2021-03-17 00:20:...|2022-11-14 01:53:...|\n",
            "|      The Politician|              Comedy|     a ser anunciado|2019-09-27|    1|Renewed|2021-03-17 00:20:...|2022-11-14 01:53:...|\n",
            "|      Super Monsters| childrens-animation|2 seasons, 16 epi...|2017-10-13|    1|Renewed|2021-03-17 00:20:...|2022-11-14 01:53:...|\n",
            "|Kulipari: Dream W...| childrens-animation|1 season, 10 epis...|2018-11-20|    1|Pending|2021-03-17 00:20:...|2022-11-14 01:53:...|\n",
            "|Inside the Real N...|         Docu-series|1 season, 3 episodes|2018-12-14|    1|Pending|2021-03-17 00:20:...|2022-11-14 01:53:...|\n",
            "|         Cable Girls|        Period drama|3 seasons, 24 epi...|2017-04-28|    1|Renewed|2021-03-17 00:20:...|2022-11-14 01:53:...|\n",
            "|             Haunted|              Horror|1 season, 6 episodes|2018-10-19|    1|Pending|2021-03-17 00:20:...|2022-11-14 01:53:...|\n",
            "|   Nailed It! Mexico|             Reality|1 season, 6 episodes|2019-02-08|    1|Pending|2021-03-17 00:20:...|2022-11-14 01:53:...|\n",
            "|Super Monsters Mo...| childrens-animation|1 season, 5 episodes|2019-06-07|    1|Pending|2021-03-17 00:20:...|2022-11-14 01:53:...|\n",
            "|             Busted!|Korean language v...|1 season, 10 epis...|2018-05-04|    1|Renewed|2021-03-17 00:20:...|2022-11-14 01:53:...|\n",
            "|Sword Gai: The An...|        Supernatural|2 seasons, 24 epi...|2018-03-23|    1|Pending|2021-03-17 00:20:...|2022-11-14 01:53:...|\n",
            "|Cupcake & Dino: G...| childrens-animation|2 seasons, 26 epi...|2018-07-27|    1|Pending|2021-03-17 00:20:...|2022-11-14 01:53:...|\n",
            "|      Selling Sunset|             Reality|1 season, 8 episodes|2019-03-22|    1|Pending|2021-03-17 00:20:...|2022-11-14 01:53:...|\n",
            "|  Somebody Feed Phil|  Travel documentary|2 seasons, 12 epi...|2018-01-12|    1|Renewed|2021-03-17 00:20:...|2022-11-14 01:53:...|\n",
            "|        Roman Empire|    Historical drama|3 seasons, 15 epi...|2016-11-11|    1|Pending|2021-03-17 00:20:...|2022-11-14 01:53:...|\n",
            "|The Boss Baby: Ba...| childrens-animation|2 seasons, 26 epi...|2018-04-06|    1|Pending|2021-03-17 00:20:...|2022-11-14 01:53:...|\n",
            "|        Chef's Table|        Culinary art|6 volumes, 30 epi...|2015-04-26|    1|Renewed|2021-03-17 00:20:...|2022-11-14 01:53:...|\n",
            "|Norm Macdonald Ha...|           Talk show|1 season, 10 epis...|2018-09-14|    1|Pending|2021-03-17 00:20:...|2022-11-14 01:53:...|\n",
            "|            Trinkets| Coming-of-age drama|1 season, 10 epis...|2019-06-14|    1|Pending|2021-03-17 00:20:...|2022-11-14 01:53:...|\n",
            "|      The Chosen One|      Thriller drama|     a ser anunciado|2019-06-28|    1|Pending|2021-03-17 00:20:...|2022-11-14 01:53:...|\n",
            "+--------------------+--------------------+--------------------+----------+-----+-------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o-264NPV1RWw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}